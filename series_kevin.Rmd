 
---
title: "Predicción con series temporales"
author: "Kevin Craig Alisauskas"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: yes
    toc_depth: 2
    number_sections: yes
subtitle: Ciencia de Datos en Negocio, Máster Ciencia de Datos
---

```{r include = FALSE}
knitr::opts_chunk$set(warning = FALSE, tidy = TRUE)

# fig.width = 8, fig.height = 6,
```


```{r include=FALSE}
# Especificamos las librerías necesarias

packages = c("tidyverse", "knitr", 'readr', 'lubridate', 'dplyr', 'tidyr', 'forecast', 'seasonal', 'readxl')

package.check <- lapply(packages, FUN = function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE)
    library(x, character.only = TRUE)
  }
})

```

# Introducción y descripción.

## Enunciado

En el archivo adjunto series.xlsx bajo tu nombre hay una serie medida mensualmente o trimestralmente para un determinado periodo temporal (la columna junto a los valores representa, en un formato no homogéneo, las fechas a las que corresponde cada uno de los valores). La mayoría de las series corresponden a la Comunidad Valenciana, hay unas pocas de España.

Además del archivo de series.xlsx puedes encontrar otros archivos xlsx, que contienen algunos regresores potenciales para las series, útiles si especificas un modelo regARIMA. En el nombre de cada uno de estos archivos se indica: 
* el año de inicio de la serie para los cuales los regresores del correspondiente archivo son de utilidad.
* la frecuencia (mensual o trimestral) asociada a los regresores.
* si deberían emplearse para series de España (ES) o de la Comunidad Valenciana.

Tu objetivo en esta tarea consiste en predecir (sobre la serie original y para la serie desestacionalizada) los valores de tu serie para 2018 (con un horizonte de 1 mes/trimestre, 2 meses/trimestres, …..., 12 meses/4 trimestres) entre un conjunto de alternativas. Selecciona al menos un modelo de la clase ETS (librería forecast), un modelo de la clase regARIMA (librería seasonal) y un modelo de los considerados sencillos. 

Para seleccionar modelos adecuados dentro de cada clase, utiliza los valores de la serie hasta 2017 (prediciendo secuencialmente, y para los diferentes horizontes, los valores de 2016 y 2017, utilizando exclusivamente los valores previos de la serie) y genera las predicciones para 2018 con todos ellos. Valora la calidad predictiva de las diferentes especificaciones en el conjunto de comprobación para selección y en el conjunto de test para cada uno de los horizontes. En las especificaciones regARIMA es necesario considerar, además de los regresores incluidos en los archivos suministrados, los regresores incluidos en el propio programa como la pascua móvil (Easter) o el ciclo semanal (Trading day).
Refleja todos los resultados alcanzados, con una justificación adecuada de los mismos, en un informe.

# Carga de Datos y análisis introductorio.

Nuestra serie muestra la evolución del IBC (Importaciones en Bienes de Consumo en millones de euros) entre 2006 y 2018, de forma mensual, es decir, que la periodicidad esperada será anual.

Comenzamos cargando los datos, almacenándolos como una serie temporal y realizando un plot.

```{r}

series <- read_excel("time_series.xlsx", col_names = c("Fecha", "IBC"), skip = 4)
series_ts <- ts(series[['IBC']], start = c(2006, 1, 1), frequency = 12)

ggplot2::autoplot(series_ts, colour = "red") + ggtitle("Serie temporal (IBC entre 2006 y 2018)") + xlab("Tiempo") + ylab("IBC")

```

Observamos la tendencia lineal ascendente (sobretodo a partir de 2010) y una cierta estacionalidad. La varianza parece constante (no tenemos heterocedasticidad), por lo que trataremos con un esquema de tipo aditivo $$ X_t \sim T_t + S_t + E_t $$.

Ahora mostramos la serie descompuesta con el esquema Aditivo, mostramos la serie, la tendencia, la estacionalidad (El resultado de sustraer la tendencia a la serie original) y los residuos (resultado de sustraer la tendencia y la componente estacional).

```{r}

ggplot2::autoplot(fit_add <- stl(series_ts, s.window = "periodic")) + ggtitle("Descomposición de la serie temporal como Aditiva")

```

Como vemos, la tendencia tiene un marcado carácter lineal, con algunas componentes que seguramente sean sucesos particulares (especialmente la bajada en 2009, en la que se registra el nivel más bajo del PIB). La componente estacional se muestra claramente, teniendo ciclos cada 2 años (al ser tener frecuencia anual...) muy marcados. Por último, los residuos parecen aleatorios, pero vamos a realizar un análisis de ellos para verlo claramente.

```{r}

checkresiduals(fit_add$time.series[, 3])

```

Observamos en la función de autocorrelación algunos "palos significativos", es posible que corresponndan a estacionalidad sistemática (semana santa...). Por otra parte, la distribución de residuos se asemeja a una gaussiana, indicando una descomposición satisfactoria.

# Análisis y predicción.

A la hora de analizar la serie o modelizarla, tomaremos tanto la serie original como la serie desestacionalizada. Recordamos que la serie original era *series_ts*, a la desestacionalizada la llamaremos *seas_ts*. Ahora la crearemos con el paquete _seasonal_ y las compararemos.

```{r}

seas_ts <- seas(series_ts)
plot(seas_ts)

```

Comprobamos que la nueva serie desestacionalizada resulta mucho más suave al quitar tanto la estacionalidad como los efectos de calendario.

## Split en train, validacion y test.

Antes de empezar a predecir necesitamos dividir en conjuntos de train, validación y test. Usaremos la serie hasta 2016 como conjunto train, los años 2016 y 2017 como validación (secuencial, se irán agregando datos a train para generar predicciones y seleccionar los mejores modelos) y el año 2018 como test. Todo esto lo haremos tanto para la serie original como desestacionalizada.

Serie desestacionalizada:

```{r}

# Extraemos la serie temporal del calculo desestacionalizado.
seas_ts <- seas_ts$data[, 1]

seas_ts_train <- window(seas_ts, end = c(2015, 12))
seas_ts_val <- window(seas_ts, start = c(2016, 1), end = c(2017, 12))
seas_ts_test <- window(seas_ts, start = c(2018, 1))

cierto <- length(seas_ts) == length(seas_ts_train) + length(seas_ts_val) + length(seas_ts_test)
print(paste0("La longitud de la serie desestacionalizada es igual a la suma de las series train, validación y test: ", cierto))

```

Serie original:

```{r}

ts_train <- window(series_ts, end = c(2015, 12))
ts_val <- window(series_ts, start = c(2016, 1), end = c(2017, 12))
ts_test <- window(series_ts, start = c(2018, 1))

cierto <- length(series_ts) == length(ts_train) + length(ts_val) + length(ts_test)
print(paste0("La longitud de la serie original es igual a la suma de las series train, validación y test: ", cierto))

```

*Nota*: Para valorar la precisión de los métodos realizaremos una predicción secuencial con el conjunto de validación con cada modelo, realizando un total de 24 modelos (2 años) y obteniendo su suma de error cuadrático (RSS, residual sum of squares), esta técnica es llamada Hold-Out Cross Validation, en concreto Leave-One-Out, porque realizamos la predicción para un único item de validación (mes) cada vez.

## Modelos sencillos.

Primero vamos crear una función para realizar el cálculo del error de Cross Validation con las funciones sencillas:

```{r}

CV_error_simp <- function(train, val, modelo, fixed_params = NaN, test = FALSE){
  
  # Por defecto calculamos el error de validación, si en su lugar quisiéramos calcular el error test...
  if(test){
    
    ifelse(is.na(fixed_params), params <- list(train, h = 12), params <- append(list(train, h = 12), fixed_params))
    
    mod <- do.call(modelo, params)
    res <- (mod$mean - val[1:12])^2
    
  }
  else{
    
    # Fijamos los parámetros
    ifelse(is.na(fixed_params), params <- list(train, h = 1), params <- append(list(train, h = 1), fixed_params))
  
    mod <- do.call(modelo, params)
    res <- (mod$mean[1] - val[1])^2
  
    # Realizamos un bucle sobre cada mes del conjunto de validación
    for(i in 1:(length(val) - 1)){
  
      # Creamos los parámetros
      new_train <- append(train, val[1:i])
      ifelse(is.na(fixed_params), params <- list(new_train, h = 1), params <- append(list(new_train, h = 1), fixed_params))
  
      # Creamos el modelo
      mod <- do.call(modelo, params)
      res <- c(res, (mod$mean[1] - val[i + 1])^2)
    
    }
    
  }
  
  # Devolvemos la suma de errores al cuadrado.
  return(sum(res))
  
}

```

Vamos a empezar a predecir para modelos sencillos. Usaremos las dos series y los modelos naïve estacional y de deriva (drift), que son simples sin llegar a ser totalmente absurdos.

```{r}

# Seasonal Naive method.
seas_snaive_error <- CV_error_simp(seas_ts_train, seas_ts_val, snaive)
snaive_error <- CV_error_simp(ts_train, ts_val, snaive)

# Método de la deriva
seas_deriva_error <- CV_error_simp(seas_ts_train, seas_ts_val, rwf, fixed_params = list(drift = TRUE))
deriva_error <- CV_error_simp(ts_train, ts_val, rwf, fixed_params = list(drift = TRUE))


res_table <- data.frame("Error snaive desestacionalizada" =  seas_snaive_error, "Error snaive original" = snaive_error, "Error deriva desestacionlizada" = seas_deriva_error, "Error deriva original" = deriva_error)

print(res_table)
```

Al analizar los RSS de cada método sobre cada una de las dos series, observamos que los errores en la serie desestacoinlizada son mucho menores, lógicamente, ya que es una serie mucho mas suave y sencilla de predecir. En cuanto a la precisión, notamos que el error tanto en la serie original como en la desestacionlizada del método de la deriva es menor, por lo que nos quedaremos con ese método de cara a la comparación final.

## Modelos de clase ETS.

Vamos crear una función para realizar el cálculo con la función ets:

```{r}

CV_error_ets <- function(train, val, modelo, fixed_params = NaN, test = FALSE){
  
  # Por defecto calculamos el error de validación, si en su lugar quisiéramos calcular el error test...
  if(test){
    
    ifelse(is.na(fixed_params), params <- list(train), params <- append(list(train), fixed_params))
    
    mod <- do.call(modelo, params)
    mod_pred <- forecast(mod, h = 12)
    res <- (mod_pred$mean - val[1:12])^2
    
  }
  else{
    
    # Fijamos los parámetros
    ifelse(is.na(fixed_params), params <- list(train), params <- append(list(train), fixed_params))
  
    mod <- do.call(modelo, params)
    mod_pred <- forecast(mod, h = 1)
    res <- (mod_pred$mean[1] - val[1])^2
  
    # Realizamos un bucle sobre cada mes del conjunto de validación
    for(i in 1:(length(val) - 1)){
  
      # Creamos los parámetros
      new_train <- append(train, val[1:i])
      ifelse(is.na(fixed_params), params <- list(new_train), params <- append(list(new_train), fixed_params))
  
      # Creamos el modelo
      mod <- do.call(modelo, params)
      mod_pred <- forecast(mod, h = 1)
      res <- c(res, (mod_pred$mean[1] - val[i + 1])^2)
    
    }
    
  }
  
  # Devolvemos la suma de errores al cuadrado.
  return(sum(res))
  
}

```

Ahora vamos a entrar en métodos de alisado exponencial (ETS = Error, Trend, Seasonal), una forma de media móvil que tiene en cuenta cada uno de los 3 componentes en los que consideramos, se descompone una serie temporal. 

A partir del análisis previo de la serie, hemos considerado que tratamos un esquema Aditivo tanto en Tendencia como en Estacionalidad, por lo que probaremos variando la clase de Error entre Aditivo y Multiplicativo, además, aunque en la práctica no tiene sentido, ya que el modelo va variando según agregamos los datos de validación, realizaremos un ajuste automático comparativo.

```{r}

# ETS method (Error = Aditivo, Trend = Aditivo, Seasonal = Aditivo, aunque en la serie desestacionalizada la compoenente Seasonal habrá de ser Nula).
seas_ets_error <- CV_error_ets(seas_ts_train, seas_ts_val, ets, fixed_params = list("AAN"))
ets_error <- CV_error_ets(ts_train, ts_val, ets, fixed_params = list("AAN"))

# ETS method (Error = Multiplicativo, Trend = Multiplicativo, Seasonal = Aditivo, aunque en la serie desestacionalizada la compoenente Seasonal habrá de ser Nula).
seas_ets_error_mult <- CV_error_ets(seas_ts_train, seas_ts_val, ets, fixed_params = list("MMN"))
ets_error_mult <- CV_error_ets(ts_train, ts_val, ets, fixed_params = list("MMN"))

# ETS method Ajuste Automático.
seas_ets_error_aut <- CV_error_ets(seas_ts_train, seas_ts_val, ets)
ets_error_aut <- CV_error_ets(ts_train, ts_val, ets)

res_table <- data.frame("Error ets desestacionalizada" =  seas_ets_error, "Error ets original" = ets_error, "Error ets desestacionlizada mult" = seas_ets_error_mult, "Error ets original mult" = ets_error_mult, "Error ets desestacionalizada automatico" = seas_ets_error_aut, "Error ets original automatico" = ets_error_aut)

print(res_table)

```

Observamos los errores en la serie desestacionalizada mucho más reducidos, como en los casos sencillos. En cuanto a la serie original, observamos cierta mejora al usar un esquema multiplicativo tanto para el error como para la tendencia. También cabe notar que el ajuste automático para cada iteración no introduce ninguna mejora respecto al MMN. Así pues, nos quedamos con un esquema Multiplicativo-Multiplicativo-Dependiente (el término dependiente corresponde a Nulo en el caso de validación, ya que perdemos estacionalizad al introducir términos no múltiplos de la estacionalizad original, 12, y a Aditivo en el caso de test, ya que no tenemos heterocedasticidad).

